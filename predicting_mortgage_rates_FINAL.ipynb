{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Mortgage Rates from Government Data (FINAL)\n",
    "\n",
    "### This code is developed as a part of the following Capstone competition for Microsoft MPP Data Scientist Certification:\n",
    "\n",
    "https://www.datasciencecapstone.org/competitions/18/mortgage-rates-from-government-data/\n",
    "\n",
    "### Training and test datasets are provided as a part of this repo.\n",
    "\n",
    "### The purpose of the code is to calculate morgate rates given the government data. This is a regression problem.\n",
    "### CatBoostRegressor machine learning model is used. Hyperparameter tuning using GridSearch with Cross Validation was also applied.\n",
    "\n",
    "### Detailed report can be found in this [PDF document](REPORT_github_version.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas\n",
    "!pip install --upgrade catboost\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade scipy\n",
    "!pip install --upgrade seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " disable automatic scrolling of notebook output\n",
    "\n",
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import time,datetime\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Acquiring the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the training dataset\n",
    "training_values = pd.read_csv('training_inputs.csv')\n",
    "training_labels = pd.read_csv('training_labels.csv')\n",
    "train = pd.merge(training_values,training_labels,on='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us view it\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many rows and features (plus label) we have \n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for redundant rows\n",
    "print(train.row_id.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINDING: It seems that we have no redundant row_id entries in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data types for the training dataset\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert \"co-applicant\" from boolean to integer\n",
    "train['co_applicant'] = train['co_applicant'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check it again\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the test (validation) dataset\n",
    "test = pd.read_csv('test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us view the test (validation) dataset\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how many rows and features we have - naturally, we do not have the label.\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for redundant rows\n",
    "print(test.row_id.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: It seems that we have no redundant row_id entries in the test dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data types for the test dataset\n",
    "print(test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert \"co-applicant\" to boolean integer\n",
    "test['co_applicant'] = test['co_applicant'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data types for the training dataset\n",
    "print(test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Capstone Challange 1 - Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION : get basic stats for 'rate_spread'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rate Spread Min: %.1f' % (training_labels['rate_spread'].min()))\n",
    "print('Rate Spread Max: %.1f' % (training_labels['rate_spread'].max()))\n",
    "print('Rate Spread Mean: %.1f' % (training_labels['rate_spread'].mean()))\n",
    "print('Rate Spread Median: %.1f' % (training_labels['rate_spread'].median()))\n",
    "print('Rate Spread Std Dev: %.1f' % (training_labels['rate_spread'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: draw histogram for 'rate_spread'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram(my_df, cols, bins = 200):\n",
    "    for col in cols:\n",
    "        fig = pyplot.figure(figsize=(6,6)) # define plot area\n",
    "        ax = fig.gca() # define axis    \n",
    "        my_df[col].plot.hist(ax = ax, bins = bins) # Use the plot.hist method on subset of the data frame\n",
    "        ax.set_title('Histogram of ' + col) # Give the plot a main title\n",
    "        ax.set_xlabel(col) # Set text for the x axis\n",
    "        ax.set_ylabel('Frequency')# Set text for y axis\n",
    "        pyplot.show()\n",
    "        \n",
    "num_cols = ['rate_spread']    \n",
    "plot_histogram(train, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION : compare avg \"rate_spread\" between 'applicant_ethnicity = 1' vs 'applicant_ethnicity = 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use boxplot which gives us a lot of information including outliers\n",
    "sns.boxplot(x='applicant_ethnicity',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the mean rate spread for \"applicant_etnicity=1.0\"\n",
    "train[train.applicant_ethnicity == 1.0].rate_spread.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the mean rate spread for \"applicant_etnicity=3.0\"\n",
    "train[train.applicant_ethnicity == 3.0].rate_spread.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINDING: *Applicants where applicant_ethnicity=3 have a higher rate spread on average than where applicant_ethnicity=1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION : compare avg \"rate_spread\" between 'sex = 1' vs 'sex = 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use boxplot which gives us a lot of information including outliers\n",
    "sns.boxplot(x='applicant_sex',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the mean rate spread for \"applicant_sex=1.0\"\n",
    "train[train.applicant_sex == 1.0].rate_spread.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the mean rate spread for \"applicant_sex=2.0\"\n",
    "train[train.applicant_sex == 2.0].rate_spread.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINDING: Applicants where applicant_sex=1 have a lower rate spread on average than where applicant_sex=2.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: for applicants in state 43, get correlation between 'income' and 'loan amount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = train[train.state_code == 43.0].applicant_income\n",
    "loan = train[train.state_code == 43.0].loan_amount\n",
    "corr_value = income.corr(loan)\n",
    "print(corr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us print the correlatin graph\n",
    "pyplot.scatter(income,loan)\n",
    "pyplot.xlabel('Applicant Income')\n",
    "pyplot.ylabel('Loan Amount')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINDING: *A higher applicant income is associated with a higher loan amount, on average.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: limiting just to state 48 and ignoring where county is missing (missing value being -1) analyze 'rate_spread' for different counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 'rate_spread' and 'county_code' for 'state_code == 48\n",
    "temp_df = train[train.state_code == 48.0][['county_code','rate_spread']]\n",
    "\n",
    "# drop the rows where 'county_code' = -1.0\n",
    "temp_df.drop(temp_df[temp_df.county_code == -1.0].index, inplace=True)\n",
    "\n",
    "# draw the boxplot\n",
    "sns.boxplot(x='county_code',y='rate_spread',data=temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In state 48, the average rate spread across counties varies substantially, ranging from around 1% to around 7%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: Looking just at states 2 and 3 and just loan types 1, 2, and 3, compare avg rate spread between states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "temp_df = train[((train.loan_type == 1.0) | (train.loan_type == 2.0) | (train.loan_type == 3.0))]\n",
    "print(temp_df.shape)\n",
    "temp_df2 = temp_df[(temp_df.state_code == 2.0) | (temp_df.state_code == 3.0)]\n",
    "print(temp_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average rate spread in state 2 vs the overall rate spread among states 2 and 3.\n",
    "m1 = temp_df2[temp_df2.state_code == 2.0].rate_spread.mean()\n",
    "print('Avg rate spread for state 2: %.2f' % m1)\n",
    "\n",
    "m2 = temp_df2.rate_spread.mean()\n",
    "print('Avg rate spread for states 2 and 3: %.2f'  %m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average rate spread in state 3 vs the overall rate among states 2 and 3.\n",
    "m1 = temp_df2[temp_df2.state_code == 3.0].rate_spread.mean()\n",
    "print('Avg rate spread for state 3: %.2f' % m1)\n",
    "\n",
    "m2 = temp_df2.rate_spread.mean()\n",
    "print('Avg rate spread for states 2 and 3: %.2f'  %m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average rate spread in state 2 vs the overall rate in state 3\n",
    "\n",
    "m1 = temp_df2[temp_df2.state_code == 2.0].rate_spread.mean()\n",
    "print('Avg rate spread for state 2: %.2f' % m1)\n",
    "\n",
    "m2 = temp_df2[temp_df2.state_code == 3.0].rate_spread.mean()\n",
    "print('Avg rate spread for state 3: %.2f'  %m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loan types 1, 2, and 3, the average rate spread in state 2 is higher than for the corresponding loan type in state 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Engineering**\n",
    "\n",
    "### Remove outlier for dependent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us see the outliers in a boxplot\n",
    "sns.boxplot(y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUT OFF VALUE FOR TRAINING DATASET\n",
    "cut_off = 50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check the number of outlier values\n",
    "train[(train['rate_spread']>cut_off)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the cutoff\n",
    "train = train[train.rate_spread < cut_off]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are given the information that a value of '-1' indicates missing value for the following columns:\n",
    "# msa_md, state_code, county_code\n",
    "# if such a value exists, we will replace it with NaN\n",
    "train['msa_md'].replace(-1.0, np.NaN,inplace=True)\n",
    "train['state_code'].replace(-1.0, np.NaN,inplace=True)\n",
    "train['county_code'].replace(-1.0, np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us see what percentage of the total data is missing\n",
    "def missing_values_table(df):\n",
    "        mis_val = df.isna().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it is time to impute missing values\n",
    "# if a feature is numeric, then use the mean()\n",
    "# for categorical features, use mode()\n",
    "train['state_code'].fillna(train['state_code'].mode()[0], inplace=True)\n",
    "train['applicant_income'].fillna(train['applicant_income'].mean(), inplace=True)\n",
    "train['population'].fillna(train['population'].mean(), inplace=True)\n",
    "train['minority_population_pct'].fillna(train['minority_population_pct'].mean(), inplace=True)\n",
    "train['ffiecmedian_family_income'].fillna(train['ffiecmedian_family_income'].mean(), inplace=True)\n",
    "train['tract_to_msa_md_income_pct'].fillna(train['tract_to_msa_md_income_pct'].mean(), inplace=True)\n",
    "train['number_of_owner-occupied_units'].fillna(train['number_of_owner-occupied_units'].mean(), inplace=True)\n",
    "train['number_of_1_to_4_family_units'].fillna(train['number_of_1_to_4_family_units'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values in the training dataset after imputing\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values for testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are given that a value of '-1' indicates missing value for the following columns:\n",
    "# msa_md, state_code, county_code\n",
    "# if such a value exists, we will replace it with NaN\n",
    "test['msa_md'].replace(-1.0, np.NaN,inplace=True)\n",
    "test['state_code'].replace(-1.0, np.NaN,inplace=True)\n",
    "test['county_code'].replace(-1.0, np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values in the test dataset\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are given that a value of '-1' indicates missing value for the following columns:\n",
    "# msa_md, state_code, county_code\n",
    "# if such a value exists, we will replace it with NaN\n",
    "test['state_code'].fillna(test['state_code'].mode()[0], inplace=True)\n",
    "test['applicant_income'].fillna(test['applicant_income'].mean(), inplace=True)\n",
    "test['population'].fillna(test['population'].mean(), inplace=True)\n",
    "test['minority_population_pct'].fillna(test['minority_population_pct'].mean(), inplace=True)\n",
    "test['ffiecmedian_family_income'].fillna(test['ffiecmedian_family_income'].mean(), inplace=True)\n",
    "test['tract_to_msa_md_income_pct'].fillna(test['tract_to_msa_md_income_pct'].mean(), inplace=True)\n",
    "test['number_of_owner-occupied_units'].fillna(test['number_of_owner-occupied_units'].mean(), inplace=True)\n",
    "test['number_of_1_to_4_family_units'].fillna(test['number_of_1_to_4_family_units'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values in the test dataset after imputing\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the statistics of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display statistics\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: The mean() values and minx/max ranges differ between features. We need to normalize these features.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets recall the data types\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating histograms of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram_with_overlay(the_array, x_title, the_flag):\n",
    "    \n",
    "    pyplot.hist(the_array, alpha=0.5, bins=50, density=True)\n",
    "\n",
    "    if(the_flag==True):\n",
    "        # find minimum and maximum of xticks, so we know\n",
    "        # where we should compute theoretical distribution\n",
    "        xt = pyplot.xticks()[0]  \n",
    "        xmin, xmax = min(xt), max(xt)  \n",
    "        lnspc = np.linspace(xmin, xmax, len(the_array))\n",
    "\n",
    "        m, s = stats.norm.fit(the_array) # get mean and standard deviation  \n",
    "        pdf_g = stats.norm.pdf(lnspc, m, s) # now get theoretical values in our interval  \n",
    "        # Plot some fancy text to show us what the parameters of the distribution are (mean and standard deviation)\n",
    "        pyplot.text(x=np.min(the_array), y=0.1, s=r\"$\\mu=%0.1f$\" % m + \"\\n\" + r\"$\\sigma=%0.1f$\" % s, color='r')\n",
    "        pyplot.plot(lnspc, pdf_g, label=\"Normal\") # plot it\n",
    "\n",
    "    # Standard plot stuff\n",
    "    pyplot.xlabel(x_title)\n",
    "    pyplot.title('Histogram of ' + x_title )\n",
    "    pyplot.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.rcParams[\"figure.figsize\"]=5,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['loan_amount'], \"Loan Amount\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print skewness value\n",
    "print(train['loan_amount'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Significant right skew is observed for the loan_amount.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['applicant_income'], \"Applicant_income\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print skewness value\n",
    "print(train['applicant_income'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Significant right skew is observed for the applicant_income.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['population'], \"Population\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print skewness value\n",
    "print(train['population'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Significant right skew is observed for the population.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['minority_population_pct'], \"minority_population_pct\",False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: The histogram for minority_population_pct seems to be exponential.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['ffiecmedian_family_income'], \"ffiecmedian_family_income\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print skewness value\n",
    "print(train['ffiecmedian_family_income'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Some small right skew is observed for ffiecmedian_family_income.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['tract_to_msa_md_income_pct'], \"tract_to_msa_md_income_pct\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print skewness value\n",
    "print(train['tract_to_msa_md_income_pct'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Significant left skew is observed for tract_to_msa_md_income_pct.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['number_of_owner-occupied_units'], \"number_of_owner-occupied_units\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print skewness value\n",
    "print(train['number_of_owner-occupied_units'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Some right skew is observed for number_of_owner-occupied_units.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_table(col_name):\n",
    "    # Get the value counts and percentages for the specific column\n",
    "    value_counts = train[col_name].value_counts().sort_index()\n",
    "    percentages = train[col_name].value_counts(normalize=True).sort_index() * 100\n",
    "    percentages = percentages.round(2) # Limit to 2 digits of accuracy\n",
    "\n",
    "\n",
    "    # Concatenate the value counts and percentages into a DataFrame\n",
    "    table = pd.concat([value_counts, percentages], axis=1)\n",
    "    table.columns = ['count', 'percentage']\n",
    "\n",
    "    # Print the table\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'loan type' \n",
    "# 1 -- Conventional (any loan other than FHA, VA, FSA, or RHS loans)\n",
    "# 2 -- FHA-insured (Federal Housing Administration)\n",
    "# 3 -- VA-guaranteed (Veterans Administration)\n",
    "# 4 -- FSA/RHS (Farm Service Agency or Rural Housing Service)\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"loan_type\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('loan_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: It seems that most of the loans are \"FHA-insured\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'property type' \n",
    "# 1 -- One to four-family (other than manufactured housing)\n",
    "# 2 -- Manufactured housing\n",
    "# 3 -- Multifamily\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"property_type\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('property_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: It seems that '1-4 family' homes are most financed. Also there are no multifamily entries in the training dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'loan purpose' \n",
    "# 1 -- Home purchase\n",
    "# 2 -- Home improvement\n",
    "# 3 -- Refinancing\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"loan_purpose\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('loan_purpose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Most loans are for home purchase.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'occupancy' \n",
    "# 1 -- Owner-occupied as a principal dwelling\n",
    "# 2 -- Not owner-occupied\n",
    "# 3 -- Not applicable\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"occupancy\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('occupancy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Most loans are for principal dwelling.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'preapproval'  requirement\n",
    "# 1 -- Preapproval was requested\n",
    "# 2 -- Preapproval was not requested\n",
    "# 3 -- Not applicable\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"preapproval\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('preapproval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Preapproval was not required for most loans.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'applicant ethnicity'\n",
    "# 1 -- Hispanic or Latino\n",
    "# 2 -- Not Hispanic or Latino\n",
    "# 3 -- Information not provided by applicant in mail, Internet, or telephone application\n",
    "# 4 -- Not applicable\n",
    "# 5 -- No co-applicant\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"applicant_ethnicity\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('applicant_ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Mortgages were rewarded mostly to \"not hispanic or latino\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'applicant race'\n",
    "# 1 -- American Indian or Alaska Native\n",
    "# 2 -- Asian\n",
    "# 3 -- Black or African American\n",
    "# 4 -- Native Hawaiian or Other Pacific Islander\n",
    "# 5 -- White\n",
    "# 6 -- Information not provided by applicant in mail, Internet, or telephone application\n",
    "# 7 -- Not applicable\n",
    "# 8 -- No co-applicant\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"applicant_race\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('applicant_race')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Loan approvals were overwhelmingly granted to whites.*\n",
    "#### *FINDING: There are no rows where applicant_race = 8.0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'applicant sex'\n",
    "# 1 -- Male\n",
    "# 2 -- Female\n",
    "# 3 -- Information not provided by applicant in mail, Internet, or telephone application\n",
    "# 4 or 5 -- Not applicable\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"applicant_sex\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('applicant_sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Most loans were granted to males.* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: There are no rows where applicant_sex = 5.0.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'co applicant'\n",
    "# 0 -- no spouse\n",
    "# 1 -- spouse\n",
    "\n",
    "# Let's view the distribution\n",
    "pyplot.figure(figsize=(20, 5)) \n",
    "sns.countplot(y=\"co_applicant\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table('co_applicant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Almost twice as many mortgages are granted to no-spouse applicants (single applicants).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Relationships between the categorical features and the dependent variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'loan type' \n",
    "# 1 -- Conventional (any loan other than FHA, VA, FSA, or RHS loans)\n",
    "# 2 -- FHA-insured (Federal Housing Administration)\n",
    "# 3 -- VA-guaranteed (Veterans Administration)\n",
    "# 4 -- FSA/RHS (Farm Service Agency or Rural Housing Service)\n",
    "\n",
    "pyplot.figure(figsize=(10, 10)) \n",
    "sns.boxplot(x='loan_type',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: The average rate spread is higher for conventional loans.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'property type' \n",
    "# 1 -- One to four-family (other than manufactured housing)\n",
    "# 2 -- Manufactured housing\n",
    "# 3 -- Multifamily\n",
    "\n",
    "pyplot.figure(figsize=(10,10)) \n",
    "sns.boxplot(x='property_type',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: One-to-four family loans have the lowest average rate_spread*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'loan purpose' \n",
    "# 1 -- Home purchase\n",
    "# 2 -- Home improvement\n",
    "# 3 -- Refinancing\n",
    "\n",
    "pyplot.figure(figsize=(10,10)) \n",
    "sns.boxplot(x='loan_purpose',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Home reimprovement loans have a higher average rate spread.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'occupancy' \n",
    "# 1 -- Owner-occupied as a principal dwelling\n",
    "# 2 -- Not owner-occupied\n",
    "# 3 -- Not applicable\n",
    "\n",
    "pyplot.figure(figsize=(10,10)) \n",
    "sns.boxplot(x='occupancy',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Unknown or \"not applicable\" occupancy has the highest average loan spread.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'preapproval'  requirement\n",
    "# 1 -- Preapproval was requested\n",
    "# 2 -- Preapproval was not requested\n",
    "# 3 -- Not applicable\n",
    "\n",
    "pyplot.figure(figsize=(10,10)) \n",
    "sns.boxplot(x='preapproval',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Preapproval was not a significant requirement.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'applicant ethnicity'\n",
    "# 1 -- Hispanic or Latino\n",
    "# 2 -- Not Hispanic or Latino\n",
    "# 3 -- Information not provided by applicant in mail, Internet, or telephone pplication\n",
    "# 4 -- Not applicable\n",
    "# 5 -- No co-applicant\n",
    "\n",
    "pyplot.figure(figsize=(10,10)) \n",
    "sns.boxplot(x='applicant_ethnicity',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: If ethnicity information is not provided by the applicant, the average rate spread is much higher. THIS IS VERY ALARMING.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'applicant race'\n",
    "# 1 -- American Indian or Alaska Native\n",
    "# 2 -- Asian\n",
    "# 3 -- Black or African American\n",
    "# 4 -- Native Hawaiian or Other Pacific Islander\n",
    "# 5 -- White\n",
    "# 6 -- Information not provided by applicant in mail, Internet, or telephone application\n",
    "# 7 -- Not applicable\n",
    "# 8 -- No co-applicant\n",
    "\n",
    "pyplot.figure(figsize=(10,15)) \n",
    "sns.boxplot(x='applicant_race',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: Average rate spread is much higher for \"American Indian or Alaska Natives\".*\n",
    "#### *FINDING: Similar to ethnicity, if race information is not provided by the applicant, the standard deviation for rate spread is much greater than others.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'applicant sex'\n",
    "# 1 -- Male\n",
    "# 2 -- Female\n",
    "# 3 -- Information not provided by applicant in mail, Internet, or telephone application\n",
    "# 4 or 5 -- Not applicable\n",
    "\n",
    "pyplot.figure(figsize=(10,10)) \n",
    "sns.boxplot(x='applicant_sex',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: While the average rate spread is pretty much equal, if the applicant does not specify gender, then the standard deviation of rate spread is higher.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the frequency distribution of 'co applicant'\n",
    "# 0 -- no spouse\n",
    "# 1 -- spouse\n",
    "\n",
    "pyplot.figure(figsize=(10,10)) \n",
    "sns.boxplot(x='co_applicant',y='rate_spread',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *FINDING: There is not much difference in resulting rate spread for different co applicant types.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming  the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply log transformation to 'loan_amount' since its histogram had skew\n",
    "# we are adding a new feature\n",
    "train['log_of_loan_amount'] = np.log(train['loan_amount'])\n",
    "# check the histogram after log transformation\n",
    "plot_histogram_with_overlay(train['log_of_loan_amount'], \"Log of loan_amount\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply log transformation to 'applicant_income' since its histogram had skew\n",
    "# we are adding a new feature\n",
    "train['log_of_applicant_income'] = np.log(train['applicant_income'])\n",
    "# check the histogram after log transformation\n",
    "plot_histogram_with_overlay(train['log_of_applicant_income'], \"Log of applicant_income\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply log transformation to 'population' since its histogram had skew\n",
    "# we are adding a new feature\n",
    "train['log_of_population'] = np.log(train['population'])\n",
    "# check the histogram after log transformation\n",
    "plot_histogram_with_overlay(train['log_of_population'], \"Log of Population\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying square root transformation (Boxcox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "# we will apply square root transformation to 'minority_population_pct' \n",
    "# since its histogram had a decaying exponential skew\n",
    "# we are adding a new feature\n",
    "train['sqrt_of_minority_population_pct'] = boxcox(train['minority_population_pct'],0.5)\n",
    "# check the histogram after log transformation\n",
    "plot_histogram_with_overlay(train['sqrt_of_minority_population_pct'], \"Sqrt of minority_population_pct\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply log transformation to 'ffiecmedian_family_income' since its histogram had skew\n",
    "# we are adding a new feature\n",
    "train['log_of_ffiecmedian_family_income'] = np.log(train['ffiecmedian_family_income'])\n",
    "# check the histogram after log transformation\n",
    "plot_histogram_with_overlay(train['log_of_ffiecmedian_family_income'], \"log_of_ffiecmedian_family_income\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply log transformation to 'tract_to_msa_md_income_pct' since its histogram had skew\n",
    "# we are adding a new feature\n",
    "train['log_of_tract_to_msa_md_income_pct'] = np.log(train['tract_to_msa_md_income_pct'])\n",
    "# check the histogram after log transformation\n",
    "plot_histogram_with_overlay(train['log_of_tract_to_msa_md_income_pct'], \"log_of_tract_to_msa_md_income_pct\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply log transformation to 'number_of_owner-occupied_units' since its histogram had skew\n",
    "# we are adding a new feature\n",
    "train['log_of_number_of_owner-occupied_units'] = np.log(train['number_of_owner-occupied_units'])\n",
    "# check the histogram after log transformation\n",
    "plot_histogram_with_overlay(train['log_of_number_of_owner-occupied_units'], \"log_of_number_of_owner-occupied_units\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will apply log transformation to 'number_of_1_to_4_family_units' since its histogram had skew\n",
    "# we are adding a new feature\n",
    "train['log_of_number_of_1_to_4_family_units'] = np.log(train['number_of_1_to_4_family_units'])\n",
    "# check the histogram after log transformation\n",
    "plot_histogram_with_overlay(train['log_of_number_of_1_to_4_family_units'], \"log_of_number_of_1_to_4_family_units\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning msa_md\n",
    "def bin_msa_md(x):\n",
    "    if 49 >= x >= 0: return 0\n",
    "    elif 99 >= x >= 50: return 1\n",
    "    elif 149 >= x >= 100: return 2\n",
    "    elif 199 >= x >= 150: return 3\n",
    "    elif 249 >= x >= 200: return 4\n",
    "    elif 299 >= x >= 250: return 5\n",
    "    elif 349 >= x >= 300: return 6\n",
    "    elif 399 >= x >= 350: return 7\n",
    "    elif 449 >= x >= 400: return 8\n",
    "    else : return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['msa_md_group'] = train['msa_md'].map(bin_msa_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['msa_md_group'], \"msa_md_group\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['county_code'], \"county_code\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning county_code\n",
    "\n",
    "def bin_county_code(x):\n",
    "    if 49 >= x >= 0: return 0\n",
    "    elif 99 >= x >= 50: return 1\n",
    "    elif 149 >= x >= 100: return 2\n",
    "    elif 199 >= x >= 150: return 3\n",
    "    elif 249 >= x >= 200: return 4\n",
    "    elif 299 >= x >= 250: return 5\n",
    "    elif 349 >= x >= 300: return 6\n",
    "    elif 399 >= x >= 350: return 7\n",
    "    elif 449 >= x >= 400: return 8\n",
    "    else : return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['county_group'] = train['county_code'].map(bin_county_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['county_group'], \"county_group\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['lender'], \"lender\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning lender\n",
    "\n",
    "def bin_lender(x):\n",
    "    if 499 >= x >= 0: return 0\n",
    "    elif 999 >= x >= 500: return 1\n",
    "    elif 1499 >= x >= 1000: return 2\n",
    "    elif 1999 >= x >= 1500: return 3\n",
    "    elif 2499 >= x >= 2000: return 4\n",
    "    elif 2999 >= x >= 2500: return 5\n",
    "    elif 3499 >= x >= 3000: return 6\n",
    "    elif 3999 >= x >= 3500: return 7\n",
    "    elif 4499 >= x >= 4000: return 8\n",
    "    else : return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lender_group'] = train['lender'].map(bin_lender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['lender_group'], \"lender_group\",False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the data types for categorical features of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the resulting data types for training dataset\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(test['loan_amount'], \"loan_amount\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['log_of_loan_amount'] = np.log(test['loan_amount'])\n",
    "plot_histogram_with_overlay(test['log_of_loan_amount'], \"Log of loan_amount\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(test['applicant_income'], \"applicant_income\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['log_of_applicant_income'] = np.log(test['applicant_income'])\n",
    "plot_histogram_with_overlay(test['log_of_applicant_income'], \"Log of applicant_income\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(test['population'], \"population\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['log_of_population'] = np.log(test['population'])\n",
    "plot_histogram_with_overlay(test['log_of_population'], \"Log of Population\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(test['minority_population_pct'], \"minority_population_pct\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "test['sqrt_of_minority_population_pct'] = boxcox(test['minority_population_pct'],0.5)\n",
    "plot_histogram_with_overlay(test['sqrt_of_minority_population_pct'], \"Sqrt of minority_population_pct\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(test['ffiecmedian_family_income'], \"ffiecmedian_family_income\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['log_of_ffiecmedian_family_income'] = np.log(test['ffiecmedian_family_income'])\n",
    "plot_histogram_with_overlay(test['log_of_ffiecmedian_family_income'], \"log_of_ffiecmedian_family_income\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(test['tract_to_msa_md_income_pct'], \"tract_to_msa_md_income_pct\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['log_of_tract_to_msa_md_income_pct'] = np.log(test['tract_to_msa_md_income_pct'])\n",
    "plot_histogram_with_overlay(test['log_of_tract_to_msa_md_income_pct'], \"log_of_tract_to_msa_md_income_pct\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(test['number_of_owner-occupied_units'], \"number_of_owner-occupied_units\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['log_of_number_of_owner-occupied_units'] = np.log(test['number_of_owner-occupied_units'])\n",
    "plot_histogram_with_overlay(test['log_of_number_of_owner-occupied_units'], \"log_of_number_of_owner-occupied_units\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_with_overlay(train['number_of_1_to_4_family_units'], \"number_of_1_to_4_family_units\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['log_of_number_of_1_to_4_family_units'] = np.log(test['number_of_1_to_4_family_units'])\n",
    "plot_histogram_with_overlay(train['log_of_number_of_1_to_4_family_units'], \"log_of_number_of_1_to_4_family_units\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['msa_md_group'] = test['msa_md'].map(bin_msa_md)\n",
    "test['county_group'] = test['county_code'].map(bin_county_code)\n",
    "test['lender_group'] = test['lender'].map(bin_lender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.rcParams[\"figure.figsize\"]=30,30\n",
    "\n",
    "corr = train.corr()\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 1.0})\n",
    "# pyplot.figure(figsize=(15,8))\n",
    "a = sns.heatmap(corr, annot=True, fmt='.2f')\n",
    "rotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "roty = a.set_yticklabels(a.get_yticklabels(), rotation=30)\n",
    "pyplot.savefig('corr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The higher correlations are shown as white."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the data types for categorical features of the training and test datasets for the Cat Boost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the urrent data types for training dataset\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype({\"loan_type\": str, \n",
    "                    \"property_type\": str,\n",
    "                    \"loan_purpose\": str,\n",
    "                    \"occupancy\": str,\n",
    "                    \"preapproval\": str,\n",
    "                    \"msa_md\": str,\n",
    "                    \"state_code\": str,\n",
    "                    \"county_code\": str,\n",
    "                    \"applicant_ethnicity\": str,\n",
    "                    \"applicant_race\": str,\n",
    "                    \"applicant_sex\": str,\n",
    "                    \"lender\": str,\n",
    "                    \"co_applicant\": str,\n",
    "                    \"msa_md_group\" : str,\n",
    "                    \"county_group\" : str,\n",
    "                    \"lender_group\" : str\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the resulting data types for training dataset\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the current data types for test dataset\n",
    "print(test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.astype({\"loan_type\": str, \n",
    "                    \"property_type\": str,\n",
    "                    \"loan_purpose\": str,\n",
    "                    \"occupancy\": str,\n",
    "                    \"preapproval\": str,\n",
    "                    \"msa_md\": str,\n",
    "                    \"state_code\": str,\n",
    "                    \"county_code\": str,\n",
    "                    \"applicant_ethnicity\": str,\n",
    "                    \"applicant_race\": str,\n",
    "                    \"applicant_sex\": str,\n",
    "                    \"lender\": str,\n",
    "                    \"co_applicant\": str,\n",
    "                    \"msa_md_group\" : str,\n",
    "                    \"county_group\" : str,\n",
    "                    \"lender_group\" : str\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the resulting data types for test dataset\n",
    "print(test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the features matrix and target array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a training set for modeling and validation set to check model performance\n",
    "X_train = train.drop(['row_id','loan_amount','applicant_income','population','minority_population_pct',\n",
    "                      'ffiecmedian_family_income','tract_to_msa_md_income_pct',\n",
    "                      'number_of_owner-occupied_units','number_of_1_to_4_family_units',\n",
    "#                     'msa_md',\n",
    "#                      'msa_md_group'\n",
    "#                    'county_code',\n",
    "#                      'country_group'\n",
    "#                      'lender',\n",
    "#                      'lender_group'\n",
    "                      'rate_spread'], axis=1)\n",
    "y_train = train.rate_spread\n",
    "\n",
    "X_test = test.drop(['row_id','loan_amount','applicant_income','population','minority_population_pct',\n",
    "                      'ffiecmedian_family_income','tract_to_msa_md_income_pct',\n",
    "                      'number_of_owner-occupied_units','number_of_1_to_4_family_units',\n",
    "#                     'msa_md',\n",
    "#                      'msa_md_group'\n",
    "#                    'county_code',\n",
    "#                      'country_group'\n",
    "#                      'lender',\n",
    "#                      'lender_group'\n",
    "#                     'lender'\n",
    "                   ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model scoring using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed for the Cat Boost model\n",
    "categorical_features_indices = np.where(X_train.dtypes == object)[0]\n",
    "print(categorical_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# define the model and set the initial parameters for CatBoostRegressor model\n",
    "model=CatBoostRegressor(iterations=200, depth=6, learning_rate=0.1, loss_function='RMSE')\n",
    "\n",
    "\n",
    "# set the parameters for KFold Cross Validation\n",
    "num_folds = 3\n",
    "random_seed = 1234\n",
    "scoring_metric = 'r2'\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True,random_state=random_seed)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring_metric, \n",
    "                             fit_params={'cat_features':categorical_features_indices,'logging_level': 'Silent'})\n",
    "\n",
    "task_duration = (time.time() - start_time)\n",
    "\n",
    "\n",
    "msg = \"Mean: %f \\t StdDev: (%f)\" % (cv_results.mean(), cv_results.std())\n",
    "print(msg)\n",
    "\n",
    "print(\"CV Scoring - Running Time: {}\".format(datetime.timedelta(seconds=task_duration)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using GridSearch with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the parameter search grid\n",
    "parameters = {'depth'         : [6,10,12],\n",
    "              'learning_rate' : [0.1,0.2],\n",
    "              'iterations'    : [200, 400,800]\n",
    "             }\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True,random_state=random_seed)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid = parameters, cv = kfold, n_jobs=-1)\n",
    "grid.fit(X_train, y_train,cat_features=categorical_features_indices,verbose=False)\n",
    "\n",
    "task_duration = (time.time() - start_time)\n",
    "\n",
    "print(\"GridSearchCV Parameter Tuning - Running Time: {}\".format(datetime.timedelta(seconds=task_duration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results from Grid Search\n",
    "print(\"\\n========================================================\")\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"========================================================\")    \n",
    "    \n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid.best_estimator_)\n",
    "    \n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid.best_score_)\n",
    "\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)\n",
    "    \n",
    "print(\"\\n ========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the best parameter to final training of the model\n",
    "optimal_parameters = grid.best_params_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with optimal parameters\n",
    "\n",
    "best_model = CatBoostRegressor(iterations=optimal_parameters[\"iterations\"],depth=optimal_parameters[\"depth\"],\n",
    "                          learning_rate=optimal_parameters[\"learning_rate\"], loss_function='RMSE')\n",
    "\n",
    "\n",
    "best_model.fit(X_train,y_train,cat_features=categorical_features_indices,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "def feature_importance(model, data):\n",
    "    \"\"\"\n",
    "    Function to show which features are most important in the model.\n",
    "    ::param_model:: Which model to use?\n",
    "    ::param_data:: What data to use?\n",
    "    \"\"\"\n",
    "    fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': data.columns})\n",
    "    fea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\n",
    "    _ = fea_imp.plot(kind='barh', x='col', y='imp', figsize=(20, 10))\n",
    "    return fea_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displlay information on feature importance\n",
    "feature_importance(best_model, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and submission of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the model predictions using the model with optimally tuned parameters\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for submission\n",
    "submission = pd.DataFrame(data=predictions, columns=['rate_spread'])\n",
    "submission['row_id'] = test['row_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to CSV file\n",
    "header = ['row_id','rate_spread']\n",
    "submission.to_csv('predicting_mortgage_rates_FINAL.csv', columns=header, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The resulting CSV file was uploaded to public site of the competition. We get a score of 0.76 which No:12 in the public scoreboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
